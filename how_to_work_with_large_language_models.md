# 如何使用大语言模型

## 大语言模型的工作原理

[大语言模型][大语言模型博客文章]是将文本映射到文本的函数。给定一个文本输入字符串，大语言模型会预测应该出现的文本。

大语言模型的神奇之处在于，通过大量文本的训练减小预测误差，最终学会了对这些预测有用的概念。例如，它们学会：

* 如何拼写
* 语法的工作原理
* 如何改述
* 如何回答问题
* 如何进行对话交流
* 如何用多种语言书写
* 如何编写代码
* 等等。

所有这些功能都不是编程而来，它们都是作为训练的结果而出现的。

GPT-3驱动了[各种软件产品][GPT3 Apps Blog Post]，包括生产应用、教育应用、游戏等等。

## 如何控制大语言模型

对于大语言模型的所有输入中，最具影响力的是文本提示。

可以通过以下几种方式提示大语言模型输出结果：

* **指令**：告诉模型你想要什么
* **完成**：引导模型完成你想要的开始部分
* **示范**：向模型展示你想要的示例，可以用以下方式：
  * 在提示中提供少量示例
  * 在微调训练数据集中提供数百或数千个示例

以下是每种提示的示例。

### 指令提示

指令遵循模型（例如，`text-davinci-003`或以`text-`开头的任何模型）是专门设计用于遵循指令的模型。将指令编写在提示的顶部（或底部或两者兼而有之），模型将尽最大努力遵循指令，然后停止。指令可以详细说明，因此不用担心编写一个明确详细说明所需输出的段落。

指令提示示例：

```text
从下面的引用中提取作者的姓名。
“有些人认为，智慧物种在扩展到外太空之前就已经灭绝了。如果他们是正确的，那么夜空的寂静便是墓地的沉默。”
― 泰德·强,《呼吸》
```

输出：

```text
泰德·强
```
### 完成提示示例
完成风格提示模式有利于大语言模型尝试生成它们认为最有可能出现的文本。为了引导模型，可以尝试开始提供一个模式或句子，以便模型生成你想要看到的输出。与直接指令相比，这种方式需要更多的细心和调试。此外，模型不一定知道何时停止生成文本，因此你通常需要使用停止序列或后处理技术来截断超出所需的文本。

完成指令示例：

```text
“有些人认为，智慧物种在扩展到外太空之前就已经灭绝了。如果他们是正确的，那么夜空的寂静便是墓地的沉默。”
― 泰德·强,《呼吸》
这段引用的作者是
```
输出：

```text
泰德·强
```

### 示范提示示例
类似于完成风格提示模式，示范提示可以向模型展示您想让它执行的任务。这种方法有时被称为few-shot learning，因为模型可以对提示中提供的几个示例中进行学习。

示范提示示例：

```text
“当理智的思维一遍又一遍地被迫面对不可能的事情时，它别无选择，只能适应。”
—— N.K.杰米辛，《第五季》
作者：N.K.杰米辛

“有些人类理论认为，智慧种族在扩展到外太空之前就已经灭绝了。如果他们是正确的，那么夜空的寂静就是坟墓的沉默。”
—— 泰德·强，《呼吸》
作者：
```
输出：

```text
泰德·强
```
###微调提示示例

有了足够的训练示例，您可以[微调][微调文档]一个自定义模型。在这种情况下，由于模型可以从提供的训练数据中学习任务，因此无需包括说明。但是，包括分隔符序列（例如 `->` 或 `###` 或任何不常出现在输入中的字符串）可以帮助提醒模型何时结束以及输出何时开始。如果没有分隔符序列，则模型可能输出不是你希望看到的答案。

微调提示示例（针对已经使用类似完成提示的模型进行自定义训练）：

```text
“有些人推测，智能物种在扩展到外层空间之前就已经灭绝了。如果他们是对的，那么夜空的寂静是墓地的宁静。”
― 泰德·张，《呼吸》

###


```

输出：

```text
泰德·张
```

## 代码能力

大型语言模型不仅在文本方面表现出色 - 它们也可以在代码方面表现出色。 OpenAI 的专用代码模型称为[Codex]。

Codex 为[超过 70 种产品][Codex应用程序博客文章]提供了支撑，包括：

* [GitHub Copilot](https://copilot.github.com/)（在 VS Code 和其他 IDE 中自动完成代码）
* [Pygma](https://pygma.app/)（将 Figma 设计转换为代码）
* [Replit](https://replit.com/)（具有“解释代码”按钮和其他功能）
* [Warp](https://www.warp.dev/)（具有人工智能命令搜索的智能终端）
* [Machinet](https://machinet.net/)（编写 Java 单元测试模板）

请注意，与遵循说明的文本模型（例如 `text-davinci-002`）不同，Codex 没有受过训练以遵循说明。因此，需要多关注设计良好的提示。

### 更多提示建议

有关更多提示示例，请访问[OpenAI 示例][OpenAI示例]。

总体来说，输入提示是改进模型输出的最佳方式。您可以尝试一些小技巧：

* **提供更明确的指示。** 例如，如果你想要输出一个逗号分隔的列表，则要求它返回一个逗号分隔的列表。如果你想让它在不知道答案时说“我不知道”，则告诉它“如果你不知道答案，请说‘我不知道’”。
* **提供更好的示例。** 如果你打算在提示中提供示例，请确保你的示例多样化且高质量。
* **要求模型像专家一样回答。** 明确要求模型产生高质量的输出或像专家写的输出，可以促使模型给出更高质量的答案，因为它认为专家会写出这样的答案。例如，“以下答案是正确的、高质量的，是由专家编写的。”
* **引导模型写出其推理过程的一系列步骤。** 例如，在你的回答前加上类似“[让我们逐步思考](https://arxiv.org/pdf/2205.11916v1.pdf)”的东西。在给出最终答案之前，要求模型解释它的推理过程，这样可以增加最终答案的一致性和正确性。

[微调文档]: https://beta.openai.com/docs/guides/fine-tuning
[Codex Apps博客文章]: https://openai.com/blog/codex-apps/
[大语言模型博客文章]: https://openai.com/blog/better-language-models/
[GPT3 Apps Blog Post]: https://openai.com/blog/gpt-3-apps/
[Codex应用程序博客文章]: https://openai.com/blog/codex-apps/
[Codex]: https://openai.com/blog/openai-codex/
[OpenAI示例]: https://beta.openai.com/examples

### 补充说明
OpenAI官方材料中文版翻译及人工智能重要文献编译，可关注微信公众号“量子论”了解最新进展。
